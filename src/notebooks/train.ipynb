{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65a9bbe8-c7ea-4324-90b8-105f58541c84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.3.1)\n",
      "Collecting pip\n",
      "  Downloading pip-24.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Downloading pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 23.3.1\n",
      "    Uninstalling pip-23.3.1:\n",
      "      Successfully uninstalled pip-23.3.1\n",
      "Successfully installed pip-24.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pandas\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting cupy-cuda11x\n",
      "  Downloading cupy_cuda11x-13.1.0-cp310-cp310-manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.24.1)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting fastrlock>=0.5 (from cupy-cuda11x)\n",
      "  Downloading fastrlock-0.8.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading scikit_learn-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m93.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cupy_cuda11x-13.1.0-cp310-cp310-manylinux2014_x86_64.whl (95.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.4/95.4 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25hDownloading fastrlock-0.8.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_28_x86_64.whl (51 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.13.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m100.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pytz, fastrlock, tzdata, threadpoolctl, scipy, joblib, cupy-cuda11x, scikit-learn, pandas\n",
      "Successfully installed cupy-cuda11x-13.1.0 fastrlock-0.8.2 joblib-1.4.2 pandas-2.2.2 pytz-2024.1 scikit-learn-1.5.0 scipy-1.13.1 threadpoolctl-3.5.0 tzdata-2024.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
      "Collecting cudf-cu11\n",
      "  Downloading https://pypi.nvidia.com/cudf-cu11/cudf_cu11-24.4.1-cp310-cp310-manylinux_2_28_x86_64.whl (471.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m471.9/471.9 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting cachetools (from cudf-cu11)\n",
      "  Downloading cachetools-5.3.3-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting cubinlinker-cu11 (from cudf-cu11)\n",
      "  Downloading https://pypi.nvidia.com/cubinlinker-cu11/cubinlinker_cu11-0.3.0.post2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m136.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cuda-python<12.0a0,>=11.7.1 (from cudf-cu11)\n",
      "  Downloading cuda_python-11.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: cupy-cuda11x>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (13.1.0)\n",
      "Collecting fsspec>=0.6.0 (from cudf-cu11)\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting numba>=0.57 (from cudf-cu11)\n",
      "  Downloading numba-0.59.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy<2.0a0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (1.24.1)\n",
      "Collecting nvtx>=0.2.1 (from cudf-cu11)\n",
      "  Downloading nvtx-0.2.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (740 bytes)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (23.2)\n",
      "Collecting pandas<2.2.2dev0,>=2.0 (from cudf-cu11)\n",
      "  Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Collecting protobuf<5,>=3.20 (from cudf-cu11)\n",
      "  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Collecting ptxcompiler-cu11 (from cudf-cu11)\n",
      "  Downloading https://pypi.nvidia.com/ptxcompiler-cu11/ptxcompiler_cu11-0.8.1.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (8.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m148.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyarrow<15.0.0a0,>=14.0.1 (from cudf-cu11)\n",
      "  Downloading pyarrow-14.0.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting rich (from cudf-cu11)\n",
      "  Downloading rich-13.7.1-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting rmm-cu11==24.4.* (from cudf-cu11)\n",
      "  Downloading https://pypi.nvidia.com/rmm-cu11/rmm_cu11-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11) (4.4.0)\n",
      "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda11x>=12.0.0->cudf-cu11) (0.8.2)\n",
      "Collecting llvmlite<0.43,>=0.42.0dev0 (from numba>=0.57->cudf-cu11)\n",
      "  Downloading llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu11) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu11) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu11) (2024.1)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->cudf-cu11)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->cudf-cu11) (2.16.1)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->cudf-cu11)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas<2.2.2dev0,>=2.0->cudf-cu11) (1.16.0)\n",
      "Downloading cuda_python-11.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.7/18.7 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m66.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numba-0.59.1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.7/3.7 MB\u001b[0m \u001b[31m120.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvtx-0.2.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (582 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m582.6/582.6 kB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m157.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-14.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (38.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/38.0 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cachetools-5.3.3-py3-none-any.whl (9.3 kB)\n",
      "Downloading rich-13.7.1-py3-none-any.whl (240 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.7/240.7 kB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.42.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (43.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 MB\u001b[0m \u001b[31m110.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: ptxcompiler-cu11, nvtx, cuda-python, pyarrow, protobuf, mdurl, llvmlite, fsspec, cubinlinker-cu11, cachetools, pandas, numba, markdown-it-py, rmm-cu11, rich, cudf-cu11\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 2.2.2\n",
      "    Uninstalling pandas-2.2.2:\n",
      "      Successfully uninstalled pandas-2.2.2\n",
      "Successfully installed cachetools-5.3.3 cubinlinker-cu11-0.3.0.post2 cuda-python-11.8.3 cudf-cu11-24.4.1 fsspec-2024.5.0 llvmlite-0.42.0 markdown-it-py-3.0.0 mdurl-0.1.2 numba-0.59.1 nvtx-0.2.10 pandas-2.2.1 protobuf-4.25.3 ptxcompiler-cu11-0.8.1.post1 pyarrow-14.0.2 rich-13.7.1 rmm-cu11-24.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mLooking in indexes: https://pypi.org/simple, https://pypi.nvidia.com\n",
      "Collecting cuml-cu11\n",
      "  Downloading https://pypi.nvidia.com/cuml-cu11/cuml_cu11-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1270.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 GB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: cudf-cu11==24.4.* in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (24.4.1)\n",
      "Requirement already satisfied: cupy-cuda11x>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (13.1.0)\n",
      "Collecting dask-cuda==24.4.* (from cuml-cu11)\n",
      "  Downloading dask_cuda-24.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting dask-cudf-cu11==24.4.* (from cuml-cu11)\n",
      "  Downloading https://pypi.nvidia.com/dask-cudf-cu11/dask_cudf_cu11-24.4.1-py3-none-any.whl (48 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (1.4.2)\n",
      "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (0.59.1)\n",
      "Collecting pylibraft-cu11==24.4.* (from cuml-cu11)\n",
      "  Downloading https://pypi.nvidia.com/pylibraft-cu11/pylibraft_cu11-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (823.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 MB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting raft-dask-cu11==24.4.* (from cuml-cu11)\n",
      "  Downloading https://pypi.nvidia.com/raft-dask-cu11/raft_dask_cu11-24.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (214.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.7/214.7 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting rapids-dask-dependency==24.4.* (from cuml-cu11)\n",
      "  Downloading https://pypi.nvidia.com/rapids-dask-dependency/rapids_dask_dependency-24.4.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: rmm-cu11==24.4.* in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (24.4.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from cuml-cu11) (1.13.1)\n",
      "Collecting treelite==4.1.2 (from cuml-cu11)\n",
      "  Downloading treelite-4.1.2-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==24.4.*->cuml-cu11) (5.3.3)\n",
      "Requirement already satisfied: cubinlinker-cu11 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==24.4.*->cuml-cu11) (0.3.0.post2)\n",
      "Requirement already satisfied: cuda-python<12.0a0,>=11.7.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==24.4.*->cuml-cu11) (11.8.3)\n",
      "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==24.4.*->cuml-cu11) (2024.5.0)\n",
      "Requirement already satisfied: numpy<2.0a0,>=1.23 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==24.4.*->cuml-cu11) (1.24.1)\n",
      "Requirement already satisfied: nvtx>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==24.4.*->cuml-cu11) (0.2.10)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==24.4.*->cuml-cu11) (23.2)\n",
      "Requirement already satisfied: pandas<2.2.2dev0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==24.4.*->cuml-cu11) (2.2.1)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==24.4.*->cuml-cu11) (4.25.3)\n",
      "Requirement already satisfied: ptxcompiler-cu11 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==24.4.*->cuml-cu11) (0.8.1.post1)\n",
      "Requirement already satisfied: pyarrow<15.0.0a0,>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==24.4.*->cuml-cu11) (14.0.2)\n",
      "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==24.4.*->cuml-cu11) (13.7.1)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from cudf-cu11==24.4.*->cuml-cu11) (4.4.0)\n",
      "Collecting click>=8.1 (from dask-cuda==24.4.*->cuml-cu11)\n",
      "  Downloading click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pynvml<11.5,>=11.0.0 (from dask-cuda==24.4.*->cuml-cu11)\n",
      "  Downloading pynvml-11.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting zict>=2.0.0 (from dask-cuda==24.4.*->cuml-cu11)\n",
      "  Downloading zict-3.0.0-py2.py3-none-any.whl.metadata (899 bytes)\n",
      "Collecting ucx-py-cu11==0.37.* (from raft-dask-cu11==24.4.*->cuml-cu11)\n",
      "  Downloading https://pypi.nvidia.com/ucx-py-cu11/ucx_py_cu11-0.37.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.7/7.7 MB\u001b[0m \u001b[31m134.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dask==2024.1.1 (from rapids-dask-dependency==24.4.*->cuml-cu11)\n",
      "  Downloading dask-2024.1.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting distributed==2024.1.1 (from rapids-dask-dependency==24.4.*->cuml-cu11)\n",
      "  Downloading distributed-2024.1.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting dask-expr==0.4.0 (from rapids-dask-dependency==24.4.*->cuml-cu11)\n",
      "  Downloading dask_expr-0.4.0-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting cloudpickle>=1.5.0 (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu11)\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting partd>=1.2.0 (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu11)\n",
      "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu11) (6.0.1)\n",
      "Collecting toolz>=0.10.0 (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu11)\n",
      "  Downloading toolz-0.12.1-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting importlib-metadata>=4.13.0 (from dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu11)\n",
      "  Downloading importlib_metadata-7.1.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu11) (3.1.2)\n",
      "Collecting locket>=1.0.0 (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu11)\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting msgpack>=1.0.0 (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu11)\n",
      "  Downloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: psutil>=5.7.2 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu11) (5.9.6)\n",
      "Collecting sortedcontainers>=2.0.5 (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu11)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tblib>=1.6.0 (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu11)\n",
      "  Downloading tblib-3.0.0-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: tornado>=6.0.4 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu11) (6.3.3)\n",
      "Requirement already satisfied: urllib3>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu11) (1.26.13)\n",
      "Requirement already satisfied: fastrlock>=0.5 in /usr/local/lib/python3.10/dist-packages (from cupy-cuda11x>=12.0.0->cuml-cu11) (0.8.2)\n",
      "Requirement already satisfied: llvmlite<0.43,>=0.42.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.57->cuml-cu11) (0.42.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu11==24.4.*->cuml-cu11) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu11==24.4.*->cuml-cu11) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<2.2.2dev0,>=2.0->cudf-cu11==24.4.*->cuml-cu11) (2024.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->cudf-cu11==24.4.*->cuml-cu11) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->cudf-cu11==24.4.*->cuml-cu11) (2.16.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/lib/python3/dist-packages (from importlib-metadata>=4.13.0->dask==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu11) (1.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.10.3->distributed==2024.1.1->rapids-dask-dependency==24.4.*->cuml-cu11) (2.1.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->cudf-cu11==24.4.*->cuml-cu11) (0.1.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas<2.2.2dev0,>=2.0->cudf-cu11==24.4.*->cuml-cu11) (1.16.0)\n",
      "Downloading dask_cuda-24.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.6/126.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading treelite-4.1.2-py3-none-manylinux2014_x86_64.whl (810 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.9/810.9 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dask-2024.1.1-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dask_expr-0.4.0-py3-none-any.whl (161 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.7/161.7 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distributed-2024.1.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m115.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading click-8.1.7-py3-none-any.whl (97 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pynvml-11.4.1-py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading zict-3.0.0-py2.py3-none-any.whl (43 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.3/43.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Downloading importlib_metadata-7.1.0-py3-none-any.whl (24 kB)\n",
      "Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Downloading msgpack-1.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (385 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.1/385.1 kB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading tblib-3.0.0-py3-none-any.whl (12 kB)\n",
      "Downloading toolz-0.12.1-py3-none-any.whl (56 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.1/56.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sortedcontainers, zict, toolz, tblib, pynvml, msgpack, locket, importlib-metadata, cloudpickle, click, ucx-py-cu11, treelite, partd, pylibraft-cu11, dask, distributed, dask-expr, rapids-dask-dependency, dask-cudf-cu11, dask-cuda, raft-dask-cu11, cuml-cu11\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 4.6.4\n",
      "    Uninstalling importlib-metadata-4.6.4:\n",
      "      Successfully uninstalled importlib-metadata-4.6.4\n",
      "Successfully installed click-8.1.7 cloudpickle-3.0.0 cuml-cu11-24.4.0 dask-2024.1.1 dask-cuda-24.4.0 dask-cudf-cu11-24.4.1 dask-expr-0.4.0 distributed-2024.1.1 importlib-metadata-7.1.0 locket-1.0.0 msgpack-1.0.8 partd-1.4.2 pylibraft-cu11-24.4.0 pynvml-11.4.1 raft-dask-cu11-24.4.0 rapids-dask-dependency-24.4.1 sortedcontainers-2.4.0 tblib-3.0.0 toolz-0.12.1 treelite-4.1.2 ucx-py-cu11-0.37.0 zict-3.0.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!python -m pip install --upgrade pip\n",
    "!pip install scikit-learn pandas cupy-cuda11x\n",
    "!pip install --extra-index-url=https://pypi.nvidia.com cudf-cu11\n",
    "!pip install cuml-cu11 --extra-index-url=https://pypi.nvidia.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e66d9df9-52a4-4c21-bfb0-6cfd371aeb53",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'ascii' codec can't decode byte 0xc2 in position 40: ordinal not in range(128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# # Example usage:\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/output-balanced-classes-10000-or-more.json\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m---> 31\u001b[0m     json_data \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m x, y \u001b[38;5;241m=\u001b[39m parse_json(json_data)\n\u001b[1;32m     34\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mreshape(x, (x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))  \u001b[38;5;66;03m# Reshape X to (10, 64)\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.10/json/__init__.py:293\u001b[0m, in \u001b[0;36mload\u001b[0;34m(fp, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload\u001b[39m(fp, \u001b[38;5;241m*\u001b[39m, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_float\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    275\u001b[0m         parse_int\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, parse_constant\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, object_pairs_hook\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw):\n\u001b[1;32m    276\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Deserialize ``fp`` (a ``.read()``-supporting file-like object containing\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;124;03m    a JSON document) to a Python object.\u001b[39;00m\n\u001b[1;32m    278\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[38;5;124;03m    kwarg; otherwise ``JSONDecoder`` is used.\u001b[39;00m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loads(\u001b[43mfp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    294\u001b[0m         \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcls\u001b[39m, object_hook\u001b[38;5;241m=\u001b[39mobject_hook,\n\u001b[1;32m    295\u001b[0m         parse_float\u001b[38;5;241m=\u001b[39mparse_float, parse_int\u001b[38;5;241m=\u001b[39mparse_int,\n\u001b[1;32m    296\u001b[0m         parse_constant\u001b[38;5;241m=\u001b[39mparse_constant, object_pairs_hook\u001b[38;5;241m=\u001b[39mobject_pairs_hook, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkw)\n",
      "File \u001b[0;32m/usr/lib/python3.10/encodings/ascii.py:26\u001b[0m, in \u001b[0;36mIncrementalDecoder.decode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m---> 26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mascii_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xc2 in position 40: ordinal not in range(128)"
     ]
    }
   ],
   "source": [
    "dictionary = {\n",
    "  34: 0, 7: 1, 2: 2, 8: 3,\n",
    "        4: 4, 22: 5, 0: 6, 6: 7\n",
    "}\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming x contains your features and y contains your classes\n",
    "\n",
    "\n",
    "def parse_json(json_data):\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    for key, value in json_data.items():\n",
    "        encoded_array = value['x']\n",
    "        decoded_array = pickle.loads(encoded_array.encode('latin1'))\n",
    "        X.append(decoded_array)\n",
    "        y.append(value['y'])\n",
    "\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# # Example usage:\n",
    "with open('../../data/output-balanced-classes-10000-or-more.json', 'r') as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "x, y = parse_json(json_data)\n",
    "x = np.reshape(x, (x.shape[0], -1))  # Reshape X to (10, 64)\n",
    "\n",
    "# Combine x and y into a single DataFrame\n",
    "df = pd.DataFrame(x)\n",
    "df['y'] = y\n",
    "\n",
    "# Calculate the counts of each class (y)\n",
    "class_counts = df['y'].value_counts()\n",
    "\n",
    "# Filter out classes with fewer than 10,000 occurrences\n",
    "valid_classes = class_counts[class_counts >= 10000].index\n",
    "\n",
    "# Remove rows where y has fewer than 10,000 occurrences\n",
    "df_filtered = df[df['y'].isin(valid_classes)]\n",
    "df_filtered.dropna(inplace=True)\n",
    "\n",
    "# Separate x and y again\n",
    "x = df_filtered.drop(columns=['y']).values\n",
    "y = df_filtered['y'].values\n",
    "y = np.vectorize(dictionary.get)(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e2c80cd-0f25-4379-8ef3-5e99f011944f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.87379390001297\n",
      "Testing Accuracy: 0.815599262714386\n",
      "Test Predictions: [3. 7. 4. ... 2. 1. 2.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['random_forest_model.joblib']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install cuML if you haven't already\n",
    "# !pip install cuml\n",
    "\n",
    "import cupy as cp\n",
    "from cuml.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import joblib, pickle\n",
    "\n",
    "# Assuming X contains your 8x8 matrices and y contains the corresponding classes\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# # # Normalizing the data\n",
    "scaler = StandardScaler()\n",
    "X_train_normalized = scaler.fit_transform(X_train)\n",
    "X_test_normalized = scaler.transform(X_test)\n",
    "\n",
    "# Convert numpy arrays to cupy arrays for GPU acceleration\n",
    "X_train_gpu = cp.array(X_train).astype(np.float32)\n",
    "X_test_gpu = cp.array(X_test)\n",
    "y_train_gpu = cp.array(y_train).astype(np.float32)\n",
    "y_test_gpu = cp.array(y_test)\n",
    "\n",
    "# Initializing and training the Random Forest classifier\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42, n_streams=1)\n",
    "clf.fit(X_train_gpu, y_train_gpu)\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = clf.score(X_train_gpu, y_train_gpu)\n",
    "test_accuracy = clf.score(X_test_gpu, y_test_gpu)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "# Obtain predictions on the test data\n",
    "rfc_test_predictions = clf.predict(X_test_gpu)\n",
    "\n",
    "# Decode the predicted labels back to characters\n",
    "# rfc_test_predictions = label_encoder.inverse_transform(cp.asnumpy(rfc_test_predictions).astype(int))\n",
    "\n",
    "# Print or use the test predictions\n",
    "print(\"Test Predictions:\", rfc_test_predictions)\n",
    "\n",
    "# Save the trained model for later use\n",
    "joblib.dump(clf, 'random_forest_model.joblib')\n",
    "\n",
    "# with open('standard_scaler.pkl', 'wb') as file:\n",
    "#     pickle.dump(scaler, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0be6da3a-1e9a-4531-b089-d3a63e32d3ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  2,  4,  6,  7,  8, 22, 34])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5913cc96-7e0f-4c27-b847-48923384a561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2\n",
       "1    8\n",
       "2    0\n",
       "3    6\n",
       "4    7\n",
       "5    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31ae0851-685d-49e9-8fd3-e1d1c11536c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(420158,)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13692f5c-1308-4093-9547-aadb698355b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29745,)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ecfba87-68f1-45d7-b1cd-78ce8f5efd7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1., 2., 3., 4., 5., 6., 7.]),\n",
       " array([2214, 2874, 8131, 5285, 2729, 1735, 3980, 2797]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(rfc_test_predictions, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bd64eea-552f-44c3-9e01-fc4ccab3de81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data into training and testing sets...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 14\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Example data (replace with your actual data)\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# X = np.random.rand(100, 64)  # 100 samples of 8x8 matrices flattened\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# y = np.random.randint(0, 10, 100)  # 100 samples of class labels\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Splitting data into training and testing sets\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSplitting data into training and testing sets...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(\u001b[43mX\u001b[49m, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData split completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Convert numpy arrays to cupy arrays for GPU acceleration\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "import cupy as cp\n",
    "from cuml.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import joblib, pickle\n",
    "\n",
    "# Assuming X contains your 8x8 matrices and y contains the corresponding classes\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "print(\"Splitting data into training and testing sets...\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "print(\"Data split completed.\")\n",
    "\n",
    "# Convert numpy arrays to cupy arrays for GPU acceleration\n",
    "print(\"Converting numpy arrays to cupy arrays for GPU acceleration...\")\n",
    "X_train_gpu = cp.array(X_train).astype(np.float32)\n",
    "X_test_gpu = cp.array(X_test).astype(np.float32)\n",
    "y_train_gpu = cp.array(y_train)\n",
    "y_test_gpu = cp.array(y_test)\n",
    "print(\"Conversion to cupy arrays completed.\")\n",
    "\n",
    "# Explicitly convert cupy arrays to numpy arrays for compatibility with scikit-learn\n",
    "print(\"Converting cupy arrays back to numpy arrays for compatibility with scikit-learn...\")\n",
    "X_train_np = X_train_gpu.get()\n",
    "X_test_np = X_test_gpu.get()\n",
    "y_train_np = y_train_gpu.get()\n",
    "y_test_np = y_test_gpu.get()\n",
    "print(\"Conversion to numpy arrays completed.\")\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, ],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "print(\"Parameter grid defined for grid search.\")\n",
    "\n",
    "# Initializing the Random Forest classifier\n",
    "print(\"Initializing the Random Forest classifier...\")\n",
    "rf_clf = RandomForestClassifier(random_state=42, n_streams=1)\n",
    "print(\"Random Forest classifier initialized.\")\n",
    "\n",
    "# Perform grid search\n",
    "print(\"Performing grid search with cross-validation...\")\n",
    "grid_search = GridSearchCV(estimator=rf_clf, param_grid=param_grid, cv=3, n_jobs=-1, scoring='accuracy')\n",
    "grid_search.fit(X_train_np, y_train_np)\n",
    "print(\"Grid search completed.\")\n",
    "\n",
    "# Get the best model from grid search\n",
    "print(\"Extracting the best model from grid search results...\")\n",
    "best_rf_clf = grid_search.best_estimator_\n",
    "print(\"Best model extracted.\")\n",
    "\n",
    "# Evaluate the best model\n",
    "print(\"Evaluating the best model on training data...\")\n",
    "train_accuracy = best_rf_clf.score(X_train_np, y_train_np)\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "\n",
    "print(\"Evaluating the best model on testing data...\")\n",
    "test_accuracy = best_rf_clf.score(X_test_np, y_test_np)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "# Obtain predictions on the test data using the best model\n",
    "print(\"Obtaining predictions on the test data using the best model...\")\n",
    "rfc_test_predictions = best_rf_clf.predict(X_test_np)\n",
    "\n",
    "# Print or use the test predictions\n",
    "print(\"Test Predictions:\", rfc_test_predictions)\n",
    "\n",
    "# Save the best trained model for later use\n",
    "print(\"Saving the best trained model to 'best_random_forest_model.pkl'...\")\n",
    "joblib.dump(best_rf_clf, 'best_random_forest_model.pkl')\n",
    "print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dad5372b-5229-487d-9cf8-e64dc5664411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array(['disappear', 'jumpingJacks', 'leftArm', 'leftFoot',\n",
       "        'leftHandPinch', 'push', 'rest', 'tongue'], dtype='<U13'),\n",
       " array([2137, 2891, 7973, 5267, 2587, 1650, 4585, 2655]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(rfc_test_predictions, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fef0c409-21d4-4740-9a0e-32108e2bac6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0,  2,  4,  6,  7,  8, 22, 34]),\n",
       " array([29087, 29077, 15428, 15186, 13927, 23532, 10531, 11957]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "145b1dec-1b99-487e-b227-bde18e897440",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder, StandardScaler\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GradientBoostingClassifier\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import cupy as cp\n",
    "import joblib\n",
    "import pickle\n",
    "\n",
    "# Assuming X contains your 8x8 matrices and y contains the corresponding classes\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Encode y labels as numerical values\n",
    "label_encoder = LabelEncoder()\n",
    "y_train = label_encoder.fit_transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)\n",
    "\n",
    "# Normalizing the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Convert numpy arrays to cupy arrays for GPU acceleration\n",
    "X_train_gpu = cp.array(X_train)\n",
    "X_test_gpu = cp.array(X_test)\n",
    "y_train_gpu = cp.array(y_train)\n",
    "y_test_gpu = cp.array(y_test)\n",
    "\n",
    "# Initializing and training the Gradient Boosting classifier\n",
    "clf = GradientBoostingClassifier(n_estimators=1000, random_state=42)\n",
    "clf.fit(cp.asnumpy(X_train_gpu), cp.asnumpy(y_train_gpu))\n",
    "\n",
    "# Evaluate the model\n",
    "train_accuracy = clf.score(cp.asnumpy(X_train_gpu), cp.asnumpy(y_train_gpu))\n",
    "test_accuracy = clf.score(cp.asnumpy(X_test_gpu), cp.asnumpy(y_test_gpu))\n",
    "print(\"Training Accuracy:\", train_accuracy)\n",
    "print(\"Testing Accuracy:\", test_accuracy)\n",
    "\n",
    "# Obtain predictions on the test data\n",
    "gboost_test_predictions = clf.predict(cp.asnumpy(X_test_gpu))\n",
    "\n",
    "# Decode the predicted labels back to characters\n",
    "gboost_test_predictions = label_encoder.inverse_transform(gboost_test_predictions)\n",
    "\n",
    "# Print or use the test predictions\n",
    "print(\"Test Predictions:\", gboost_test_predictions)\n",
    "\n",
    "# Save the trained model for later use\n",
    "joblib.dump(clf, 'gradient_boosting_model.joblib')\n",
    "with open('label_encoder.pkl', 'wb') as file:\n",
    "    pickle.dump(label_encoder, file)\n",
    "with open('standard_scaler.pkl', 'wb') as file:\n",
    "    pickle.dump(scaler, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5104674-3f22-43be-8f69-64f552a0157e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2324041\n",
      "-rw-rw-rw- 1 root root  204338555 May 19 07:02 output-balanced-classes-10000-or-more.json\n",
      "-rw-rw-rw- 1 root root       1994 May 19 07:24 standard_scaler.pkl\n",
      "-rw-rw-rw- 1 root root        655 May 19 07:24 label_encoder.pkl\n",
      "-rw-rw-rw- 1 root root  112361717 May 19 07:33 random_forest_model.joblib\n",
      "-rw-rw-rw- 1 root root 2059025686 May 19 07:48 best_random_forest_model.pkl\n",
      "drwxrwxrwx 2 root root    1007480 May 19 09:14 .ipynb_checkpoints\n",
      "-rw-rw-rw- 1 root root      11878 May 19 10:01 Untitled.ipynb\n",
      "drwxr-xr-x 1 root root        124 May 19 14:10 ..\n",
      "-rw-rw-rw- 1 root root      59111 May 19 15:05 train.ipynb\n",
      "-rw-rw-rw- 1 root root       8024 May 19 15:06 inference.ipynb\n",
      "drwxrwxrwx 3 root root    3000221 May 19 15:06 .\n"
     ]
    }
   ],
   "source": [
    "!ls -lart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e76cf094-8bb3-4944-9651-b957cd378987",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 5, 6, ..., 6, 6, 5])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "414e78db-3464-48c2-a307-e907217512b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7]),\n",
       " array([11957, 13927, 29077, 23532, 15428, 10531, 29087, 15186]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e25c653-3d63-4066-bb01-52c5e8d9a7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
